<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Python - 爬虫之Scrapy | FSA全栈行动</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="icon" href="/img/favicon.ico">
    <script data-ad-client="ca-pub-3568502583266202" async="async" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script src="/js/global.js"></script>
    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?885476c2eae58d4aee1ab7fcfb548adb";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
      </script>
    <meta name="description" content="分享Android、iOS、Python、Vue等技术资讯、学习笔记，成功有梦想的全栈工程师，欢迎关注。">
    <meta name="keywords" content="FSA全栈行动,LinXunFeng,GitLqr,全栈技术博客,移动端,web前端,后端开发,前端框架,web前端,Android框架,iOS框架,Flutter框架,Python框架,Vue框架,技术文档,学习,面试,Java,Kotlin,object-c,Swift,Kotlin,Dart,JavaScript,js,ES6,vue,python,css3,html5,Node,git,github,markdown">
    <meta name="baidu-site-verification" content="code-Cyx4xlZmzI">
    <meta name="google-site-verification" content="_0KO4KbxdSwB-TPRQ8bRqmML8dnrx5G82GhQNZlR4HU">
    <meta name="theme-color" content="#11a8cd">
    
    <link rel="preload" href="/assets/css/0.styles.f24a96ee.css" as="style"><link rel="preload" href="/assets/js/app.978e7bf8.js" as="script"><link rel="preload" href="/assets/js/2.d8b68cf2.js" as="script"><link rel="preload" href="/assets/js/180.444a244e.js" as="script"><link rel="prefetch" href="/assets/js/10.d7f25949.js"><link rel="prefetch" href="/assets/js/100.9ebeff21.js"><link rel="prefetch" href="/assets/js/101.692c940a.js"><link rel="prefetch" href="/assets/js/102.e2f371dd.js"><link rel="prefetch" href="/assets/js/103.915d0f88.js"><link rel="prefetch" href="/assets/js/104.28cfb05a.js"><link rel="prefetch" href="/assets/js/105.093417ac.js"><link rel="prefetch" href="/assets/js/106.3cbd2542.js"><link rel="prefetch" href="/assets/js/107.64783dba.js"><link rel="prefetch" href="/assets/js/108.743f1185.js"><link rel="prefetch" href="/assets/js/109.f19942bd.js"><link rel="prefetch" href="/assets/js/11.599058ac.js"><link rel="prefetch" href="/assets/js/110.8af5f48d.js"><link rel="prefetch" href="/assets/js/111.8bd3a603.js"><link rel="prefetch" href="/assets/js/112.561e95e5.js"><link rel="prefetch" href="/assets/js/113.dc4597d6.js"><link rel="prefetch" href="/assets/js/114.0b360344.js"><link rel="prefetch" href="/assets/js/115.d3a84fe4.js"><link rel="prefetch" href="/assets/js/116.3987a675.js"><link rel="prefetch" href="/assets/js/117.06dfe4cf.js"><link rel="prefetch" href="/assets/js/118.8b183b3e.js"><link rel="prefetch" href="/assets/js/119.0f5457d8.js"><link rel="prefetch" href="/assets/js/12.da03bdf0.js"><link rel="prefetch" href="/assets/js/120.7a1fc0c6.js"><link rel="prefetch" href="/assets/js/121.c39b3bac.js"><link rel="prefetch" href="/assets/js/122.98abc6f1.js"><link rel="prefetch" href="/assets/js/123.d26b6150.js"><link rel="prefetch" href="/assets/js/124.8a5a34f6.js"><link rel="prefetch" href="/assets/js/125.ba32e31d.js"><link rel="prefetch" href="/assets/js/126.5c1160c9.js"><link rel="prefetch" href="/assets/js/127.cda7bc77.js"><link rel="prefetch" href="/assets/js/128.693e08d4.js"><link rel="prefetch" href="/assets/js/129.e6b34ba6.js"><link rel="prefetch" href="/assets/js/13.e839622d.js"><link rel="prefetch" href="/assets/js/130.a5c99ad8.js"><link rel="prefetch" href="/assets/js/131.b076989a.js"><link rel="prefetch" href="/assets/js/132.a7a08de6.js"><link rel="prefetch" href="/assets/js/133.d8849bbf.js"><link rel="prefetch" href="/assets/js/134.97755c83.js"><link rel="prefetch" href="/assets/js/135.106ce0b9.js"><link rel="prefetch" href="/assets/js/136.52554b90.js"><link rel="prefetch" href="/assets/js/137.33299b33.js"><link rel="prefetch" href="/assets/js/138.9ff58cd6.js"><link rel="prefetch" href="/assets/js/139.7cee0069.js"><link rel="prefetch" href="/assets/js/14.dfac8018.js"><link rel="prefetch" href="/assets/js/140.87424ea7.js"><link rel="prefetch" href="/assets/js/141.d610ca63.js"><link rel="prefetch" href="/assets/js/142.a63d6162.js"><link rel="prefetch" href="/assets/js/143.98b3a651.js"><link rel="prefetch" href="/assets/js/144.7349ca77.js"><link rel="prefetch" href="/assets/js/145.858d9452.js"><link rel="prefetch" href="/assets/js/146.a032b581.js"><link rel="prefetch" href="/assets/js/147.db1005fb.js"><link rel="prefetch" href="/assets/js/148.20fde4db.js"><link rel="prefetch" href="/assets/js/149.79e591ff.js"><link rel="prefetch" href="/assets/js/15.525d5dfe.js"><link rel="prefetch" href="/assets/js/150.9969db2c.js"><link rel="prefetch" href="/assets/js/151.84e062f1.js"><link rel="prefetch" href="/assets/js/152.fca6b962.js"><link rel="prefetch" href="/assets/js/153.e362f89c.js"><link rel="prefetch" href="/assets/js/154.fcadffca.js"><link rel="prefetch" href="/assets/js/155.51be41cc.js"><link rel="prefetch" href="/assets/js/156.670b7225.js"><link rel="prefetch" href="/assets/js/157.3a57cfca.js"><link rel="prefetch" href="/assets/js/158.a6d1e8ba.js"><link rel="prefetch" href="/assets/js/159.64cab194.js"><link rel="prefetch" href="/assets/js/16.d8737ba6.js"><link rel="prefetch" href="/assets/js/160.e6b7d160.js"><link rel="prefetch" href="/assets/js/161.c771a4b3.js"><link rel="prefetch" href="/assets/js/162.0aa8e10c.js"><link rel="prefetch" href="/assets/js/163.5bdad447.js"><link rel="prefetch" href="/assets/js/164.dd9e18fb.js"><link rel="prefetch" href="/assets/js/165.cfb5ecb2.js"><link rel="prefetch" href="/assets/js/166.64893c00.js"><link rel="prefetch" href="/assets/js/167.fb34d725.js"><link rel="prefetch" href="/assets/js/168.c6919fcc.js"><link rel="prefetch" href="/assets/js/169.26db219c.js"><link rel="prefetch" href="/assets/js/17.a33331a9.js"><link rel="prefetch" href="/assets/js/170.ef03e7ee.js"><link rel="prefetch" href="/assets/js/171.39efa101.js"><link rel="prefetch" href="/assets/js/172.79693a1c.js"><link rel="prefetch" href="/assets/js/173.76c28bf5.js"><link rel="prefetch" href="/assets/js/174.11305f41.js"><link rel="prefetch" href="/assets/js/175.280b1336.js"><link rel="prefetch" href="/assets/js/176.a3389684.js"><link rel="prefetch" href="/assets/js/177.d281dbdd.js"><link rel="prefetch" href="/assets/js/178.18bcec8c.js"><link rel="prefetch" href="/assets/js/179.53f26880.js"><link rel="prefetch" href="/assets/js/18.33037d59.js"><link rel="prefetch" href="/assets/js/181.255a3b9b.js"><link rel="prefetch" href="/assets/js/182.27de39cd.js"><link rel="prefetch" href="/assets/js/183.1c6eb065.js"><link rel="prefetch" href="/assets/js/184.9fbd7ef7.js"><link rel="prefetch" href="/assets/js/185.92d0c99d.js"><link rel="prefetch" href="/assets/js/186.451a3696.js"><link rel="prefetch" href="/assets/js/187.1a2ebed5.js"><link rel="prefetch" href="/assets/js/188.cc053993.js"><link rel="prefetch" href="/assets/js/189.4d003779.js"><link rel="prefetch" href="/assets/js/19.c55f5d6a.js"><link rel="prefetch" href="/assets/js/190.1c2e71d8.js"><link rel="prefetch" href="/assets/js/191.634043a1.js"><link rel="prefetch" href="/assets/js/192.dbc67b6d.js"><link rel="prefetch" href="/assets/js/193.2d74c614.js"><link rel="prefetch" href="/assets/js/194.3aeb89a1.js"><link rel="prefetch" href="/assets/js/195.233df07d.js"><link rel="prefetch" href="/assets/js/196.9d599622.js"><link rel="prefetch" href="/assets/js/197.632b3abd.js"><link rel="prefetch" href="/assets/js/198.6f968e93.js"><link rel="prefetch" href="/assets/js/199.4c89e43f.js"><link rel="prefetch" href="/assets/js/20.33fe86db.js"><link rel="prefetch" href="/assets/js/200.9a280dad.js"><link rel="prefetch" href="/assets/js/201.819c0fb7.js"><link rel="prefetch" href="/assets/js/202.faac415f.js"><link rel="prefetch" href="/assets/js/203.93272af8.js"><link rel="prefetch" href="/assets/js/204.300d7c66.js"><link rel="prefetch" href="/assets/js/205.792301d2.js"><link rel="prefetch" href="/assets/js/206.ac6ce63d.js"><link rel="prefetch" href="/assets/js/207.feec67b7.js"><link rel="prefetch" href="/assets/js/208.fe99967d.js"><link rel="prefetch" href="/assets/js/209.2076b476.js"><link rel="prefetch" href="/assets/js/21.ab5e7303.js"><link rel="prefetch" href="/assets/js/210.96e6ea16.js"><link rel="prefetch" href="/assets/js/211.247dd9b5.js"><link rel="prefetch" href="/assets/js/212.4685fa55.js"><link rel="prefetch" href="/assets/js/213.74946d32.js"><link rel="prefetch" href="/assets/js/214.815c7524.js"><link rel="prefetch" href="/assets/js/215.dc89772f.js"><link rel="prefetch" href="/assets/js/216.b129f31e.js"><link rel="prefetch" href="/assets/js/217.179a9472.js"><link rel="prefetch" href="/assets/js/218.d64bca73.js"><link rel="prefetch" href="/assets/js/219.8ec39aea.js"><link rel="prefetch" href="/assets/js/22.ec455aec.js"><link rel="prefetch" href="/assets/js/220.54a1abd8.js"><link rel="prefetch" href="/assets/js/221.cc8d8423.js"><link rel="prefetch" href="/assets/js/222.c9d4c68b.js"><link rel="prefetch" href="/assets/js/223.8925a9f3.js"><link rel="prefetch" href="/assets/js/224.1674a0b6.js"><link rel="prefetch" href="/assets/js/225.0ad155fb.js"><link rel="prefetch" href="/assets/js/226.cc75a51a.js"><link rel="prefetch" href="/assets/js/227.bba7fda3.js"><link rel="prefetch" href="/assets/js/228.9d1aa01e.js"><link rel="prefetch" href="/assets/js/229.921a7b55.js"><link rel="prefetch" href="/assets/js/23.d3a842bc.js"><link rel="prefetch" href="/assets/js/230.22550bd4.js"><link rel="prefetch" href="/assets/js/231.a489811a.js"><link rel="prefetch" href="/assets/js/232.f234e21b.js"><link rel="prefetch" href="/assets/js/233.e57b64ab.js"><link rel="prefetch" href="/assets/js/234.017947c4.js"><link rel="prefetch" href="/assets/js/235.7b08d9d3.js"><link rel="prefetch" href="/assets/js/236.09d867d0.js"><link rel="prefetch" href="/assets/js/237.de37d18d.js"><link rel="prefetch" href="/assets/js/238.42364597.js"><link rel="prefetch" href="/assets/js/239.9db374c8.js"><link rel="prefetch" href="/assets/js/24.39bed4a8.js"><link rel="prefetch" href="/assets/js/240.d71ac99a.js"><link rel="prefetch" href="/assets/js/241.353499d9.js"><link rel="prefetch" href="/assets/js/242.78820ec4.js"><link rel="prefetch" href="/assets/js/243.b9c33c58.js"><link rel="prefetch" href="/assets/js/244.a6e4e359.js"><link rel="prefetch" href="/assets/js/245.1e3e184e.js"><link rel="prefetch" href="/assets/js/246.06835c08.js"><link rel="prefetch" href="/assets/js/247.c1a39d47.js"><link rel="prefetch" href="/assets/js/248.8f11aef3.js"><link rel="prefetch" href="/assets/js/249.02019891.js"><link rel="prefetch" href="/assets/js/25.ffefd3d8.js"><link rel="prefetch" href="/assets/js/250.84625882.js"><link rel="prefetch" href="/assets/js/251.ea5e676b.js"><link rel="prefetch" href="/assets/js/252.7f2253d9.js"><link rel="prefetch" href="/assets/js/253.ebf5c371.js"><link rel="prefetch" href="/assets/js/254.692c349e.js"><link rel="prefetch" href="/assets/js/255.87ebb7e7.js"><link rel="prefetch" href="/assets/js/256.c62649b9.js"><link rel="prefetch" href="/assets/js/257.f7090194.js"><link rel="prefetch" href="/assets/js/26.ad30bb86.js"><link rel="prefetch" href="/assets/js/27.dbb4126e.js"><link rel="prefetch" href="/assets/js/28.8bd9d307.js"><link rel="prefetch" href="/assets/js/29.1a71e08e.js"><link rel="prefetch" href="/assets/js/3.5382cf65.js"><link rel="prefetch" href="/assets/js/30.42d97bb2.js"><link rel="prefetch" href="/assets/js/31.30f900c9.js"><link rel="prefetch" href="/assets/js/32.a5df6c36.js"><link rel="prefetch" href="/assets/js/33.9204b9be.js"><link rel="prefetch" href="/assets/js/34.bf2570c3.js"><link rel="prefetch" href="/assets/js/35.ac4ccec9.js"><link rel="prefetch" href="/assets/js/36.b797468c.js"><link rel="prefetch" href="/assets/js/37.9196dfa6.js"><link rel="prefetch" href="/assets/js/38.746d9db3.js"><link rel="prefetch" href="/assets/js/39.bae582ef.js"><link rel="prefetch" href="/assets/js/4.f21084fd.js"><link rel="prefetch" href="/assets/js/40.5a3d5763.js"><link rel="prefetch" href="/assets/js/41.efe92704.js"><link rel="prefetch" href="/assets/js/42.c8e276f2.js"><link rel="prefetch" href="/assets/js/43.7b5518fd.js"><link rel="prefetch" href="/assets/js/44.cb0239ea.js"><link rel="prefetch" href="/assets/js/45.411caf2b.js"><link rel="prefetch" href="/assets/js/46.8374a3d1.js"><link rel="prefetch" href="/assets/js/47.79a96a98.js"><link rel="prefetch" href="/assets/js/48.3318facd.js"><link rel="prefetch" href="/assets/js/49.e2fefb42.js"><link rel="prefetch" href="/assets/js/5.fb735bd1.js"><link rel="prefetch" href="/assets/js/50.30b4bfec.js"><link rel="prefetch" href="/assets/js/51.e955e801.js"><link rel="prefetch" href="/assets/js/52.3e4c5bd5.js"><link rel="prefetch" href="/assets/js/53.10b4da3e.js"><link rel="prefetch" href="/assets/js/54.bcf53f23.js"><link rel="prefetch" href="/assets/js/55.72e98f4d.js"><link rel="prefetch" href="/assets/js/56.df4b0bc5.js"><link rel="prefetch" href="/assets/js/57.024e57ae.js"><link rel="prefetch" href="/assets/js/58.b2727bae.js"><link rel="prefetch" href="/assets/js/59.f5026f0c.js"><link rel="prefetch" href="/assets/js/6.37c62a4c.js"><link rel="prefetch" href="/assets/js/60.6e09f3e9.js"><link rel="prefetch" href="/assets/js/61.fea72a18.js"><link rel="prefetch" href="/assets/js/62.db6f90d9.js"><link rel="prefetch" href="/assets/js/63.f15fa795.js"><link rel="prefetch" href="/assets/js/64.1f07e27d.js"><link rel="prefetch" href="/assets/js/65.d00ddf25.js"><link rel="prefetch" href="/assets/js/66.dc377466.js"><link rel="prefetch" href="/assets/js/67.1a858f2e.js"><link rel="prefetch" href="/assets/js/68.f0fb2148.js"><link rel="prefetch" href="/assets/js/69.960af925.js"><link rel="prefetch" href="/assets/js/7.02b44ced.js"><link rel="prefetch" href="/assets/js/70.a7fd9f5e.js"><link rel="prefetch" href="/assets/js/71.797b9ba2.js"><link rel="prefetch" href="/assets/js/72.544b7f42.js"><link rel="prefetch" href="/assets/js/73.233ea30b.js"><link rel="prefetch" href="/assets/js/74.74193aec.js"><link rel="prefetch" href="/assets/js/75.58090f19.js"><link rel="prefetch" href="/assets/js/76.70d46d82.js"><link rel="prefetch" href="/assets/js/77.ab758303.js"><link rel="prefetch" href="/assets/js/78.d40627c8.js"><link rel="prefetch" href="/assets/js/79.4a480023.js"><link rel="prefetch" href="/assets/js/8.ade06460.js"><link rel="prefetch" href="/assets/js/80.396cf990.js"><link rel="prefetch" href="/assets/js/81.86cbef81.js"><link rel="prefetch" href="/assets/js/82.70b41659.js"><link rel="prefetch" href="/assets/js/83.5e7d0691.js"><link rel="prefetch" href="/assets/js/84.8141702f.js"><link rel="prefetch" href="/assets/js/85.132eb564.js"><link rel="prefetch" href="/assets/js/86.6d6d3f06.js"><link rel="prefetch" href="/assets/js/87.3c287970.js"><link rel="prefetch" href="/assets/js/88.ab381cae.js"><link rel="prefetch" href="/assets/js/89.3fc1949f.js"><link rel="prefetch" href="/assets/js/9.cef0a42d.js"><link rel="prefetch" href="/assets/js/90.95e4cac8.js"><link rel="prefetch" href="/assets/js/91.c5c18896.js"><link rel="prefetch" href="/assets/js/92.5883fb02.js"><link rel="prefetch" href="/assets/js/93.0a36ee68.js"><link rel="prefetch" href="/assets/js/94.71a7723b.js"><link rel="prefetch" href="/assets/js/95.48f02b92.js"><link rel="prefetch" href="/assets/js/96.6f336fcd.js"><link rel="prefetch" href="/assets/js/97.d6a61a44.js"><link rel="prefetch" href="/assets/js/98.8f3aeef7.js"><link rel="prefetch" href="/assets/js/99.76c3493b.js">
    <link rel="stylesheet" href="/assets/css/0.styles.f24a96ee.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/20210131112211.jpg" alt="FSA全栈行动" class="logo"> <span class="site-name can-hide">FSA全栈行动</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="移动端" class="dropdown-title"><a href="/mobile/" class="link-title">移动端</a> <span class="title" style="display:none;">移动端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>移动端文章</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/61d6a8/" class="nav-link">Android</a></li><li class="dropdown-subitem"><a href="/pages/cb27eb/" class="nav-link">iOS</a></li><li class="dropdown-subitem"><a href="/pages/61cc74/" class="nav-link">Flutter</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/kotlin/" class="nav-link">《Kotlin快速入门进阶》笔记</a></li><li class="dropdown-subitem"><a href="/note/flutter/" class="nav-link">《Flutter从入门到实战》笔记</a></li><li class="dropdown-subitem"><a href="/note/flutter/lxf/review/" class="nav-link">《Flutter复习》笔记</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/web/" class="nav-link">前端</a></div><div class="nav-item"><a href="/backend/" class="nav-link">后端</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="内功心法" class="dropdown-title"><a href="/power/" class="link-title">内功心法</a> <span class="title" style="display:none;">内功心法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/designpattern/" class="nav-link">《深入浅出设计模式Java版》笔记</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/ea5b48/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="About" class="dropdown-title"><!----> <span class="title" style="display:;">About</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/about/LinXunFeng/" class="nav-link">LinXunFeng</a></li><li class="dropdown-item"><!----> <a href="/about/GitLqr/" class="nav-link">GitLqr</a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><div class="blogger"><img src="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/20210131111432.png"> <div class="blogger-info"><h3>公众号：FSA全栈行动</h3> <span>记录学习过程中的知识</span></div></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="移动端" class="dropdown-title"><a href="/mobile/" class="link-title">移动端</a> <span class="title" style="display:none;">移动端</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>移动端文章</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/pages/61d6a8/" class="nav-link">Android</a></li><li class="dropdown-subitem"><a href="/pages/cb27eb/" class="nav-link">iOS</a></li><li class="dropdown-subitem"><a href="/pages/61cc74/" class="nav-link">Flutter</a></li></ul></li><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/kotlin/" class="nav-link">《Kotlin快速入门进阶》笔记</a></li><li class="dropdown-subitem"><a href="/note/flutter/" class="nav-link">《Flutter从入门到实战》笔记</a></li><li class="dropdown-subitem"><a href="/note/flutter/lxf/review/" class="nav-link">《Flutter复习》笔记</a></li></ul></li></ul></div></div><div class="nav-item"><a href="/web/" class="nav-link">前端</a></div><div class="nav-item"><a href="/backend/" class="nav-link">后端</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="内功心法" class="dropdown-title"><a href="/power/" class="link-title">内功心法</a> <span class="title" style="display:none;">内功心法</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>学习笔记</h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/note/designpattern/" class="nav-link">《深入浅出设计模式Java版》笔记</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="更多" class="dropdown-title"><a href="/more/" class="link-title">更多</a> <span class="title" style="display:none;">更多</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/pages/ea5b48/" class="nav-link">逆向</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="索引" class="dropdown-title"><a href="/archives/" class="link-title">索引</a> <span class="title" style="display:none;">索引</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/" class="nav-link">分类</a></li><li class="dropdown-item"><!----> <a href="/tags/" class="nav-link">标签</a></li><li class="dropdown-item"><!----> <a href="/archives/" class="nav-link">归档</a></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="About" class="dropdown-title"><!----> <span class="title" style="display:;">About</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/about/LinXunFeng/" class="nav-link">LinXunFeng</a></li><li class="dropdown-item"><!----> <a href="/about/GitLqr/" class="nav-link">GitLqr</a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Linux音视频</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Docker</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python环境</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Python爬虫</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/pages/b960c3/" class="sidebar-link">Python - 爬虫基础与requests模块</a></li><li><a href="/pages/9c63e1/" class="sidebar-link">Python - 爬虫之数据提取</a></li><li><a href="/pages/10277d/" class="sidebar-link">Python - 爬虫之Selenium</a></li><li><a href="/pages/b576c8/" aria-current="page" class="active sidebar-link">Python - 爬虫之Scrapy</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#一、scrapy-概念和流程" class="sidebar-link">一、scrapy 概念和流程</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、概念" class="sidebar-link">1、概念</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、工作流程" class="sidebar-link">2、工作流程</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_3、各模块的具体作用" class="sidebar-link">3、各模块的具体作用</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#二、scrapy-入门使用" class="sidebar-link">二、scrapy 入门使用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、安装-scrapy" class="sidebar-link">1、安装 scrapy</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、项目开发流程" class="sidebar-link">2、项目开发流程</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_3、三个内置对象" class="sidebar-link">3、三个内置对象</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1-定位元素以及提取数据" class="sidebar-link">1）定位元素以及提取数据</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2-response-响应对象的常用属性" class="sidebar-link">2）response 响应对象的常用属性</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_4、入门实战" class="sidebar-link">4、入门实战</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#三、scrapy-数据建模-items" class="sidebar-link">三、scrapy 数据建模(items)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、数据建模" class="sidebar-link">1、数据建模</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#四、scrapy-处理翻页-request" class="sidebar-link">四、scrapy 处理翻页(Request)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、思路" class="sidebar-link">1、思路</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、实现步骤" class="sidebar-link">2、实现步骤</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_3、实战-网易招聘爬虫" class="sidebar-link">3、实战（网易招聘爬虫）</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_4、scrapy-request-的更多参数" class="sidebar-link">4、scrapy.Request 的更多参数</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#五、scrapy-模拟登录-cookie" class="sidebar-link">五、scrapy 模拟登录(cookie)</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、模拟登录的不同实现方式" class="sidebar-link">1、模拟登录的不同实现方式</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、scrapy-直接携带-cookies-获取需要登录信息的页面" class="sidebar-link">2、scrapy 直接携带 cookies 获取需要登录信息的页面</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、scrapy-request-发送-post-请求" class="sidebar-link">2、scrapy.Request 发送 post 请求</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#六、scrapy-管道的使用" class="sidebar-link">六、scrapy 管道的使用</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、pipeline-中常用的方法" class="sidebar-link">1、pipeline 中常用的方法</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、pipeline-判断数据来源" class="sidebar-link">2、pipeline 判断数据来源</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_3、pipeline-使用注意点" class="sidebar-link">3、pipeline 使用注意点</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/pages/b576c8/#七、scrapy-中间件" class="sidebar-link">七、scrapy 中间件</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_1、介绍" class="sidebar-link">1、介绍</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_2、使用方法" class="sidebar-link">2、使用方法</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_3、实现随机-user-agent-下载中间件" class="sidebar-link">3、实现随机 User-Agent 下载中间件</a></li><li class="sidebar-sub-header level3"><a href="/pages/b576c8/#_4、实现-selenium-渲染的下载中间件" class="sidebar-link">4、实现 Selenium 渲染的下载中间件</a></li></ul></li></ul></li></ul></section></li></ul> <div class="sidebar-slot sidebar-slot-bottom"><!-- 正方形 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="3508773082"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div></aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/backend/#后端" data-v-06225672>后端</a></li><li data-v-06225672><a href="/backend/#Python爬虫" data-v-06225672>Python爬虫</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/FullStackAction/" target="_blank" title="作者" class="beLink" data-v-06225672>FullStackAction</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2021-07-13</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABKFJREFUSA3tVl1oFVcQnrMbrak3QUgkya1akpJYcrUtIqW1JvFBE9LiQ5v6JmJpolbMg32rVrhgoYK0QiMY6i9Y6EMaW5D+xFJaTYItIuK2Kr3+BJNwkxBj05sQY3b3nM6cs2dv9t7NT/vQJw/sndk5M/PNzJkzewGerP+pAmy+ON8lLzUJgA8ZYxYIYZmGYRnctDaWvJJAmTtfP1pvXsBCCPP8QFcCaRkZYACgDZFO4stNIcBCajEOlmmC9XpJ9bAGCaPaPmzPl32dvLSVu3BWCTQs0XQQ6g0DYgwLIoAZbBCdW/i+781o1VVlm/410mw4h06Y7bIPHNyWDyL4FHkX03Q8SrzNhZTZriieckWt7cL6MM85YcLpsi/7O9/iXFT6MswI0DmmpkSaJ0qLxFIm3+i1THHB3zmBH3PYx9CcykcLOeQVVa7QtdxTgQgEleX2AjHYfwA+2ddV77ruGoJUbhGDI09YSNXyMpUt5ylOzxgbUmtOp7NmbNt8v3arjTBfYELmLUV+M+nSawNNAUqpT3ClJWg5I3BLT+cGW/DXNGCa6tx1aakCGEigArTn4TDIPdrXXYKCZNrHLMCOEPvHBlLQ99s9eHB7EB6NTki73CVPQ2F5MSx/uRQixfmq7rK0wYD8w8E905bnPDfwoWs/rfv93NWN/ZfvwsLIU7A09gxECyISeGJkHAau98L97tuw7NXnoPyNF8FcYGLGKsOs0mN3OEyec9esGW/ZEl945dTP34wlR2FZVQWU1q0Cw8Tr7p+hgLLNL0FPxx/Q35mA8aEUrH6nCgwEl0tn7wUiZYJnNRh6DK4UH/k0lfyrsBKdPVv/AriGIQcEDQZ65LBAGe2Rzui9Ybjz7XUppz1/uKBbyVPGkN3ZAeC6hr0x7Nr38N5+EqkoOm17xpoqR9ohQF55ERSvr4Dkr3chNfC3DMzGJlNBElW8w9nsGQvhNGIzDkXzCg8cLK951xHsFBlTJspJNi3ZFIMF2AeDV3q8DNOB+YHi6QTrChDIWDBRi5U5f+ZMfJLu3ccrqxtdxk4SKH336LFxSmkqefwU5T8fhdSdQf9IVKD6aNiwI/hnmcAZ91isYMJIaCUCx9W098+LgruikeTqzqqxKPUwqJyCPJiyemVVZBOijDGjD38Os0jOiSPL1z3SPjXNANbiNPXAdzTfukjjuknNBbyz3nwgTd3AVFqUJ5hpHlq9MveLnWwttUfoygBmvVjuikxND3znrhsELnZk7k+OjIGxeNEkomyLVta0xxn+HZhjBc4YZ/AFjHjz9u3xRZl2BN4aq9nFwWh16IrQ1aHHEd3j1+4/dB9OtH4e29A2H1DyHQRmOSfQZ1Fy7MHBTGB6J/Djq6p3OxyO2cB+4Car7v/o3GXgfAkj23+x9ID1Teoamo/SXcbvSf2PX7Vc8DdCmE1vN9di+32P9/5YR3vLnhCVGUWBjEkr3yh4H8v9CzmsbdhzOKzsJKM90iFdaTMjRPhGVsakRvOaRidljo6H6G7j+ctrJpsP+4COhDIl0La2+FS4+5mlocBaXY5QnGZysIBYoeSsl5qQzrSj/cgNrfuEzlWBfwA+EjrZyWUvpAAAAABJRU5ErkJggg==">Python - 爬虫之Scrapy<!----></h1> <div class="page-slot page-slot-top"><!-- 固定100% * 90px可显示，max-height:90px未见显示-->
     <ins class="adsbygoogle"
          style="display:inline-block;width:100%;max-height:90px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6625304284"></ins>
      <center>欢迎关注微信公众号：<a href="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/FSA_QR_bottom.png">[FSA全栈行动 👋]</a><center>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="theme-vdoing-content content__default"><h2 id="一、scrapy-概念和流程"><a href="#一、scrapy-概念和流程" class="header-anchor">#</a> 一、scrapy 概念和流程</h2> <h3 id="_1、概念"><a href="#_1、概念" class="header-anchor">#</a> 1、概念</h3> <p>Scrapy 是一个 python 编写的，被设计用于爬取网络数据、提取结构性数据的开源网络爬虫框架。</p> <ul><li>作用：少量的代码，就能够快速的抓取</li> <li>官方文档：<a href="https://scrapy-chs.readthedocs.io/zh_CN/0.24/" target="_blank" rel="noopener noreferrer">https://scrapy-chs.readthedocs.io/zh_CN/0.24/<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul> <blockquote><p>补充：Scrapy 使用了 Twisted 异步网络框架，可以加快下载速度</p></blockquote> <h3 id="_2、工作流程"><a href="#_2、工作流程" class="header-anchor">#</a> 2、工作流程</h3> <p><img src="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource20210320170901/image/20210704154838.jpg" alt="scrapy流程图"></p> <p>其流程描述如下：</p> <ol><li>爬虫中起始的 url 构造成 request 对象 --&gt; 爬虫中间件 --&gt; 引擎 --&gt; 调度器</li> <li>调度器把 request --&gt; 引擎 --&gt; 下载中间件 --&gt; 下载器</li> <li>下载器发送请求，获取 response 响应 --&gt; 下载中间件 --&gt; 引擎 --&gt; 爬虫中间件 --&gt; 爬虫</li> <li>爬虫提取 url 地址，组装成 request 对象 --&gt; 爬虫中间件 --&gt; 引擎 --&gt; 调度器，重复步骤 2</li> <li>爬虫提取数据 --&gt; 引擎 --&gt; 管道处理和保存数据</li></ol> <p>注意：</p> <ul><li>图中绿色线条表示数据的传递</li> <li>图中中间件的位置决定了其作用</li> <li>引擎处于 4 个模块中间，各个模块之间相互独立，只和引擎进行交互</li></ul> <h3 id="_3、各模块的具体作用"><a href="#_3、各模块的具体作用" class="header-anchor">#</a> 3、各模块的具体作用</h3> <table><thead><tr><th>模块</th> <th>作用</th> <th>是否实现</th></tr></thead> <tbody><tr><td>Scrapy Engine(引擎)</td> <td>总指挥：负责数据和信号在不同模块之间传递</td> <td>scrapy 已经实现</td></tr> <tr><td>Scheduler(调度器)</td> <td>一个队列，存放引擎发过来的 request 请求</td> <td>scrapy 已经实现</td></tr> <tr><td>Downloader(下载器)</td> <td>下载把引擎发过来的 request 请求，并返回给引擎</td> <td>scrapy 已经实现</td></tr> <tr><td>Spider(爬虫)</td> <td>处理引擎发来的 response，提取数据、url，并交给引擎</td> <td><strong><em>需要手写</em></strong></td></tr> <tr><td>Item Pipeline(管道)</td> <td>处理引擎传过来的数据，比如存储</td> <td><strong><em>需要手写</em></strong></td></tr> <tr><td>Downloader Middlewares(下载中间件)</td> <td>可以自定义的下载扩展，比如设置代理</td> <td>一般不用手写</td></tr> <tr><td>Spider Middlewares(爬虫中间件)</td> <td>可以自定义 requests 请求和进行 response 过滤</td> <td>一般不用手写</td></tr></tbody></table> <blockquote><p>注意：爬虫中间件 和 下载中间件 只是运行逻辑的位置不同，作用是重复的：如替换 UA 等。</p></blockquote> <h2 id="二、scrapy-入门使用"><a href="#二、scrapy-入门使用" class="header-anchor">#</a> 二、scrapy 入门使用</h2> <h3 id="_1、安装-scrapy"><a href="#_1、安装-scrapy" class="header-anchor">#</a> 1、安装 scrapy</h3> <p>scrapy 有 2 种安装方式：</p> <ul><li><p>命令：</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> scrapy
</code></pre></div></li> <li><p>pip：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>pip/pip3 <span class="token function">install</span> scrapy
</code></pre></div></li></ul> <h3 id="_2、项目开发流程"><a href="#_2、项目开发流程" class="header-anchor">#</a> 2、项目开发流程</h3> <ol><li><p>创建项目：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy startproject <span class="token operator">&lt;</span>项目名称<span class="token operator">&gt;</span>

eg:
	scrapy startproject myspider
</code></pre></div></li> <li><p>生成一个爬虫：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy genspider <span class="token operator">&lt;</span>爬虫名字<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>允许爬取的域名<span class="token operator">&gt;</span>

eg:
	<span class="token builtin class-name">cd</span> myspider
	scrapy genspider example example.com
</code></pre></div><ul><li><p>爬虫名字：作用爬虫运行时的参数</p></li> <li><p>允许爬取的域名：为对于爬虫设置的爬取范围，设置之后用于过滤要爬取的 url，如果爬取的 url 与允许的域不同则被过滤掉</p> <blockquote><p>注意：执行完命令后，myspider/spiders 目录下，会多出一个 example.py 爬虫文件</p></blockquote></li></ul></li> <li><p>提取数据：</p> <p>根据网站结构在 spider 中实现数据采集相关内容</p></li> <li><p>保存数据：</p> <p>使用 pipeline 进行数据后续处理和保存</p></li> <li><p>运行 scrapy</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy crawl <span class="token operator">&lt;</span>爬虫名字<span class="token operator">&gt;</span>
scrapy crawl <span class="token operator">&lt;</span>爬虫名字<span class="token operator">&gt;</span> <span class="token parameter variable">--nolog</span>

eg:
	scrapy crawl example
</code></pre></div><blockquote><p>注意 ：需要在项目录下执行命令；<code>--nolog</code> 可以关闭框架日志信息输出</p></blockquote></li></ol> <h3 id="_3、三个内置对象"><a href="#_3、三个内置对象" class="header-anchor">#</a> 3、三个内置对象</h3> <ul><li>request 请求对象：由 url method post_data headers 等构成</li> <li>response 响应对象：由 url body status headers 等构成</li> <li>item 数据对象：本质是字典</li></ul> <h3 id="_1-定位元素以及提取数据"><a href="#_1-定位元素以及提取数据" class="header-anchor">#</a> 1）定位元素以及提取数据</h3> <p>解析并获取 scrapy 爬虫中的数据：利用 xpath 规则字符串进行定位和提取</p> <ul><li><code>response.xpath()</code>：返回一个类似 List 的类型，其中包含的是 selector 对象，操作和列表一样，但是有一些额外方法：
<ul><li><code>extract()</code>：返回一个包含有字符串的列表</li> <li><code>extract_first()</code>：返回列表中的第一个字符串，列表为空则返回 None</li></ul></li></ul> <h3 id="_2-response-响应对象的常用属性"><a href="#_2-response-响应对象的常用属性" class="header-anchor">#</a> 2）response 响应对象的常用属性</h3> <ul><li><code>response.url</code>：当前响应的 url 地址</li> <li><code>response.request.url</code>：当前响应对应的请求的 url 地址</li> <li><code>response.headers</code>：响应头</li> <li><code>response.request.headers</code>：当前响应的请求头</li> <li><code>response.body</code>：响应体，也就是 html 代码，byte 类型</li> <li><code>response.status</code>：响应状态码</li></ul> <h3 id="_4、入门实战"><a href="#_4、入门实战" class="header-anchor">#</a> 4、入门实战</h3> <h4 id="_1-创建项目-爬虫"><a href="#_1-创建项目-爬虫" class="header-anchor">#</a> 1）创建项目&amp;爬虫</h4> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy startproject myspider
<span class="token builtin class-name">cd</span> myspider
scrapy genspider itcast itcast.cn
</code></pre></div><h4 id="_2-完善爬虫-抓取数据"><a href="#_2-完善爬虫-抓取数据" class="header-anchor">#</a> 2）完善爬虫（抓取数据）</h4> <p>在/myspider/myspider/spiders/itcast.py 中修改内容如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'itcast'</span>
    <span class="token comment"># 2.检查域名</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'itcast.cn'</span><span class="token punctuation">]</span>
    <span class="token comment"># 1.修改起始url</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://itcast.cn/channel/teacher.shtml'</span><span class="token punctuation">]</span>  <span class="token comment"># 设置起始的url，我们只需要设置就好，通常会被自动的创建成请求发送</span>

    <span class="token comment"># 3.在parse方法中实现爬取逻辑</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 解析方法，通常用于起始url对应响应的解析</span>
        <span class="token comment"># 定义对于网站的相关操作</span>
        <span class="token comment"># with open('itcast.html', 'wb') as f:</span>
        <span class="token comment">#     f.write(response.body)</span>

        <span class="token comment"># 获取所有老师节点</span>
        node_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;li_txt&quot;]'</span><span class="token punctuation">)</span>

        <span class="token comment"># 遍历老师节点列表</span>
        <span class="token keyword">for</span> node <span class="token keyword">in</span> node_list<span class="token punctuation">:</span>
            temp <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>

            <span class="token comment"># xpath方法返回的是选择器对象列表，extract()用于从选择器对象中提取数据</span>
            <span class="token comment"># temp['name'] = node.xpath('./h3/text()')[0].extract()</span>
            <span class="token comment"># temp['title'] = node.xpath('./h4/text()')[0].extract()</span>
            <span class="token comment"># temp['desc'] = node.xpath('./p/text()')[0].extract()</span>

            <span class="token comment"># xpath结果为只含有一个值的列表，可以使用extract_first()，如果为多个值则使用extract()</span>
            temp<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./h3/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            temp<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./h4/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            temp<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./p/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># {'name': [&lt;Selector xpath='./h3/text()' data='黄老师'&gt;], 'title': [&lt;Selector xpath='./h4/text()' data='高级讲师'&gt;], 'desc': [&lt;Selector xpath='./p/text()' data='15年+的软件开发与教学经验，参与中国联通VOP系统，中国联通在线计费系统...'&gt;]}</span>
            <span class="token comment"># extract()之后：</span>
            <span class="token comment"># {'name': '黄老师', 'title': '高级讲师', 'desc': '15年+的软件开发与教学经验，参与中国联通VOP系统，中国联通在线计费系统，道路交通事故救助基金管理系统等的开发工作；\r\n拥有丰富的教学经验。'}</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>temp<span class="token punctuation">)</span>

            <span class="token keyword">yield</span> temp
</code></pre></div><p>注意：</p> <ul><li><code>scrapy.Spider</code>爬虫类中必须有名为 parse 的解析</li> <li>如果网站结构层次比较复杂，也可以自定义其他解析函数</li> <li>在解析函数中提取的 url 地址如果要发送请求，则必须属于 <code>allowed_domains</code> 范围内，但是 <code>start_urls</code> 中的 url 地址不受这个限制</li> <li><code>parse()</code> 函数中使用 <code>yield</code> 返回数值。</li> <li><strong>yield 能够传递的对象只能是：BaseItem，Request，dict，None</strong></li></ul> <h4 id="_3-完善管道-保存数据"><a href="#_3-完善管道-保存数据" class="header-anchor">#</a> 3）完善管道（保存数据）</h4> <ol><li>定义一个管道类</li> <li>重写管道类的 <code>process_item()</code> 方法</li> <li><code>process_item()</code> 方法处理完 item 之后必须返回给引擎</li></ol> <p>这里直接使用创建项目时默认创建好的管道类：/myspider/myspider/pipelines/MyspiderPipeline，修改内容如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> json


<span class="token keyword">class</span> <span class="token class-name">MyspiderPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'itcast.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print('item:', item)</span>
        <span class="token comment"># 将字典数据序列化</span>
        json_data <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>item<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">',\n'</span>

        <span class="token comment"># 将数据写入文件</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>json_data<span class="token punctuation">)</span>

        <span class="token comment"># 默认使用完管道之后需要将数据返回给引擎</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">__del__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h4 id="_4-启用管道"><a href="#_4-启用管道" class="header-anchor">#</a> 4）启用管道</h4> <div class="language-python extra-class"><pre class="language-python"><code>ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'myspider.pipelines.MyspiderPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
   <span class="token comment"># 'myspider.pipelines.MyspiderPipelineOther': 301,</span>
<span class="token punctuation">}</span>
</code></pre></div><ul><li>配置项中，键为使用的管道类，管道类引用声明使用<code>.</code>进行分割，分别为：<code>项目目录.文件.管理类</code>。</li> <li>配置项中，值为管道的使用顺序，设置的数值越小越先执行，该值一般设置在 1000 以内。</li></ul> <h4 id="_5-运行爬虫"><a href="#_5-运行爬虫" class="header-anchor">#</a> 5）运行爬虫</h4> <p>在控制台运行如下命令即可运行爬虫：</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy crawl itcast
scrapy crawl itcast <span class="token parameter variable">--nolog</span>
</code></pre></div><h2 id="三、scrapy-数据建模-items"><a href="#三、scrapy-数据建模-items" class="header-anchor">#</a> 三、scrapy 数据建模(items)</h2> <h3 id="_1、数据建模"><a href="#_1、数据建模" class="header-anchor">#</a> 1、数据建模</h3> <p>通常在项目开发过程中，需要在 <code>items.py</code> 中进行数据建模</p> <h4 id="_1-为什么要建模"><a href="#_1-为什么要建模" class="header-anchor">#</a> 1）为什么要建模</h4> <ul><li>定义 item 即提前规划好哪些字段需要抓取，防止手误，因为定义好之后，在运行过程中，系统会自动检查</li> <li>配置注释一起可以清晰的知道要抓取哪些字段，没有定义的字段不能抓取，在目标字段少的时候可以使用字典代替</li> <li>使用 scrapy 的一些特定组件中需要 Item 做支持，如 scrapy 的 ImagesPipeline 管道类。</li></ul> <h4 id="_2-如何建模"><a href="#_2-如何建模" class="header-anchor">#</a> 2）如何建模</h4> <p>在 <code>items.py</code> 文件中定义发提取的字段：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MyspiderItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 讲师的名字</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 讲师的职称</span>
    desc <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 讲师的介绍</span>

<span class="token comment"># if __name__ == '__main__':</span>
<span class="token comment">#     item = MyspiderItem()</span>
<span class="token comment">#     item['name'] = 'lqr'  # ok</span>
<span class="token comment">#     item['nama'] = 'lqr'  # KeyError: 'MyspiderItem does not support field: nama'</span>
</code></pre></div><blockquote><p>注意：<code>scrapy.Item</code> 可以理解为一个更高级的 <strong>“字典”</strong>，可以对键名进行限制、校验。但切记它不是字典，如果你需要对字典进行操作，可以使用 <code>dict()</code> 将<code>scrapy.Item</code> 进行强制转换。</p></blockquote> <h4 id="_3-使用模板类"><a href="#_3-使用模板类" class="header-anchor">#</a> 3）使用模板类</h4> <p>模板类定义以后，需要在爬虫中导入并且实例化，之后的使用方法和字典相同：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># 如果报包报错有2种解决办法：</span>
<span class="token comment"># 1、PyCharm以myspider为根目录重新打开项目</span>
<span class="token comment"># 2、不以myspider为根目录的话，可以右键myspider--&gt;Make Directory as--&gt;Sources Root</span>
<span class="token keyword">from</span> myspider<span class="token punctuation">.</span>items <span class="token keyword">import</span> MyspiderItem

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> MyspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./h3/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./h4/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./p/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
		<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">yield</span> item
</code></pre></div><h4 id="_4-开发流程总结"><a href="#_4-开发流程总结" class="header-anchor">#</a> 4）开发流程总结</h4> <ol><li><p>创建项目</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy startproject 项目名
</code></pre></div></li> <li><p>明确目标</p> <ul><li>在 items.py 文件中进行建模</li></ul></li> <li><p>创建爬虫</p> <ul><li><p>创建爬虫</p> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy genspider 爬虫名 允许的域
</code></pre></div></li> <li><p>编写爬虫</p> <div class="language-shell extra-class"><pre class="language-shell"><code>修改start_urls
检查修改allowed_domains
编写解析方法
</code></pre></div></li></ul></li> <li><p>保存数据</p> <ul><li>在 <code>pipelines.py</code> 文件中定义对数据处理的管道</li> <li>在 <code>settings.py</code> 文件中注册启用管道</li></ul></li></ol> <h2 id="四、scrapy-处理翻页-request"><a href="#四、scrapy-处理翻页-request" class="header-anchor">#</a> 四、scrapy 处理翻页(Request)</h2> <h3 id="_1、思路"><a href="#_1、思路" class="header-anchor">#</a> 1、思路</h3> <ol><li>找到下一页的 url 地址</li> <li>构造 url 地址的请求对象，传递给引擎</li></ol> <h3 id="_2、实现步骤"><a href="#_2、实现步骤" class="header-anchor">#</a> 2、实现步骤</h3> <ol><li><p>确定 url 地址</p></li> <li><p>构造请求</p> <div class="language-python extra-class"><pre class="language-python"><code>scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> callback<span class="token punctuation">)</span>
</code></pre></div><ul><li><code>callback</code>：指定解析函数名称，表示该请求返回的响应使用哪一个函数进行解析</li></ul></li> <li><p>把请求交给引擎</p></li></ol> <h3 id="_3、实战-网易招聘爬虫"><a href="#_3、实战-网易招聘爬虫" class="header-anchor">#</a> 3、实战（网易招聘爬虫）</h3> <h4 id="_1-思路分析"><a href="#_1-思路分析" class="header-anchor">#</a> 1）思路分析</h4> <ol><li>获取首页数据</li> <li>寻找下一页地址，进行翻页，获取数据</li></ol> <h4 id="_2-代码实现"><a href="#_2-代码实现" class="header-anchor">#</a> 2）代码实现</h4> <ul><li>创建项目</li></ul> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy startproject wangyi

<span class="token builtin class-name">cd</span> wangyi
scrapy gespider job <span class="token number">163</span>.com
</code></pre></div><ul><li>定义模板类</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">WangyiItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    link <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    depart <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    category <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token builtin">type</span> <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    address <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    num <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    date <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>编写爬虫（抓取数据）</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> wangyi<span class="token punctuation">.</span>items <span class="token keyword">import</span> WangyiItem


<span class="token keyword">class</span> <span class="token class-name">JobSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'job'</span>
    <span class="token comment"># 2.检查修改allowed_domains</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'163.com'</span><span class="token punctuation">]</span>
    <span class="token comment"># 1.修改start_urls</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://hr.163.com/position/list.do'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 提取数据</span>
        <span class="token comment"># 获取所有职位节点列表</span>
        node_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@class=&quot;position-tb&quot;]/tbody/tr'</span><span class="token punctuation">)</span>

        <span class="token comment"># 遍历节点列表</span>
        <span class="token keyword">for</span> num<span class="token punctuation">,</span> node <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>node_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 设置过滤条件，将目标节点获取出来</span>
            <span class="token keyword">if</span> num <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                item <span class="token operator">=</span> WangyiItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[1]/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token comment"># item['link'] = 'https://hr.163.com' + node.xpath('./td[1]/a/@href').extract_first()</span>
                <span class="token comment"># response.urljoin()用于拼接相对路径的url，可以理解为自动补全</span>
                item<span class="token punctuation">[</span><span class="token string">'link'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[1]/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'depart'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'category'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[3]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'type'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[4]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'address'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[5]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'num'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[6]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'date'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[7]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token comment"># print(item)</span>
                <span class="token keyword">yield</span> item

        <span class="token comment"># 模拟翻页</span>
        part_url <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[2]/div[2]/div[2]/div/a[last()]/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 判断终止条件</span>
        <span class="token keyword">if</span> part_url <span class="token operator">!=</span> <span class="token string">'javascript:void(0)'</span><span class="token punctuation">:</span>
            next_url <span class="token operator">=</span> response<span class="token punctuation">.</span>urljoin<span class="token punctuation">(</span>part_url<span class="token punctuation">)</span>
            <span class="token comment"># 构建请求对象，并且返回给引擎</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>
                url<span class="token operator">=</span>next_url<span class="token punctuation">,</span>
                callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse
            <span class="token punctuation">)</span>
</code></pre></div><blockquote><p>注意：引擎根据爬虫 <code>yield</code> 的对象类型，将对象分配给对应的模块处理，比如：如果是模板类对象或字典，则会交给管道(Item Pipeline)；如果是 Request 对象，则会交给队列(Scheduler)。</p></blockquote> <ul><li>编写管道（存储数据）</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> json


<span class="token keyword">class</span> <span class="token class-name">WangyiPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'wangyi.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>

        str_data <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>item<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">',\n'</span>

        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>str_data<span class="token punctuation">)</span>

        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">__del__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><ul><li>启用管道</li></ul> <div class="language-python extra-class"><pre class="language-python"><code>ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'wangyi.pipelines.WangyiPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre></div><ul><li>运行爬虫</li></ul> <div class="language-shell extra-class"><pre class="language-shell"><code>scrapy crawl job <span class="token parameter variable">--nolog</span>
</code></pre></div><h4 id="_3-扩展"><a href="#_3-扩展" class="header-anchor">#</a> 3）扩展：</h4> <ul><li><p>可以在 settings 中设置 ROBOTS 协议</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># False表示忽略网站的robots.txt协议，默认为True</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
</code></pre></div></li> <li><p>可以在 settings 中设置 User-Agent：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># scrapy发送的每一个请求的默认UA都是设置的这个User-Agent</span>
USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36'</span>
</code></pre></div></li></ul> <h3 id="_4、scrapy-request-的更多参数"><a href="#_4、scrapy-request-的更多参数" class="header-anchor">#</a> 4、scrapy.Request 的更多参数</h3> <div class="language-python extra-class"><pre class="language-python"><code>scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">[</span><span class="token punctuation">,</span> callback<span class="token punctuation">,</span> method<span class="token operator">=</span><span class="token string">&quot;GET&quot;</span><span class="token punctuation">,</span> headers<span class="token punctuation">,</span> body<span class="token punctuation">,</span> cookies<span class="token punctuation">,</span> meta<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div><blockquote><p>注意：中括号[]里的参数为可选参数</p></blockquote> <p>参数解释：</p> <ul><li><strong>callback</strong>：表示当前 url 的响应交给哪个函数去处理</li> <li><strong>meta</strong>：实现数据在不同的解析函数中传递，meta 默认带有部分数据，比如下载延迟，请求深度等</li> <li>dont_filter：默认为 False，会过滤请求的 url 地址，即请求过的 url 地址不会继续被请求，对需要重复请求的 url 地址可以把它设置为 True，比如贴吧的翻页请求，页面的数据总是在变化，start_urls 中的地址会被反复请求，否则程序不会启动</li> <li>method：指定 POST 或 GET 请求</li> <li>headers：接收一个字典，其中不包括 cookies</li> <li>cookies：接收一个字典，专门放置 cookies</li> <li>body：接收 json 字符串，为 POST 的数据，发送 payload_post 请求时使用</li></ul> <h4 id="_1-meta-参数的使用"><a href="#_1-meta-参数的使用" class="header-anchor">#</a> 1）meta 参数的使用</h4> <ul><li><p>meta 的使用：</p> <ul><li>meta 可以实现数据在不同的解析函数中传递</li></ul></li> <li><p>meta 的注意事项：</p> <ul><li>meta 参数是一个字典</li> <li>meta 字典中有一个固定的键 proxy，表示代理 ip</li></ul></li> <li><p>使用举例：</p></li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>detail_url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">,</span> meta<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'item'</span><span class="token punctuation">:</span> item<span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>


<span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 获取之前传入的item</span>
    item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
</code></pre></div><h2 id="五、scrapy-模拟登录-cookie"><a href="#五、scrapy-模拟登录-cookie" class="header-anchor">#</a> 五、scrapy 模拟登录(cookie)</h2> <h3 id="_1、模拟登录的不同实现方式"><a href="#_1、模拟登录的不同实现方式" class="header-anchor">#</a> 1、模拟登录的不同实现方式</h3> <ul><li>requests 模块
<ul><li>直接携带 cookies 请求页面</li> <li>找到 url 地址，发送 post 请求存储 cookie</li></ul></li> <li>selenium（浏览器自动处理 cookie）
<ul><li>找到对应的 input 标签，输入文本点击登录</li></ul></li> <li>scrapy
<ul><li>直接携带 cookies</li> <li>找 url 地址，发送 post 请求存储 cookie</li></ul></li></ul> <h3 id="_2、scrapy-直接携带-cookies-获取需要登录信息的页面"><a href="#_2、scrapy-直接携带-cookies-获取需要登录信息的页面" class="header-anchor">#</a> 2、scrapy 直接携带 cookies 获取需要登录信息的页面</h3> <p>应用场景：</p> <ul><li>cookie 过期时间很长，常见于一些不规范的网站</li> <li>能在 cookie 过期之前把所有的数据拿到</li> <li>配合其他程序使用，比如其使用 selenium 把登录之后的 cookie 获取到并保存到本地，scrapy 发送请求之前先读取本地 cookie</li></ul> <h4 id="_1、start-url-携带-cookie-重写-start-requests-方法"><a href="#_1、start-url-携带-cookie-重写-start-requests-方法" class="header-anchor">#</a> 1、start_url 携带 cookie（重写 start_requests 方法）</h4> <p>scrapy 中 start_url 是通过 start_requests 来进行处理的，可能通过重写该方法让 start_url 携带上请求头信息，实现代码如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">Git1Spider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'git1'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'github.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://github.com/GitLqr'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        重写start_requests，发送携带cookies的Request。
        默认start_requests只是普通的get请求，不会携带自定义的头信息
        &quot;&quot;&quot;</span>
        url <span class="token operator">=</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        temp <span class="token operator">=</span> <span class="token string">'_octo=GH1.1.1045146750.1615451260; _device_id=cd8d64981fcb3fd4ba7f587873e97804'</span>
        <span class="token comment"># 把cookies字符串转成字典</span>
        cookies <span class="token operator">=</span> <span class="token punctuation">{</span>data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span> data<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> data <span class="token keyword">in</span> temp<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'; '</span><span class="token punctuation">)</span><span class="token punctuation">}</span>

        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>
            url<span class="token operator">=</span>url<span class="token punctuation">,</span>
            callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">,</span>
            cookies<span class="token operator">=</span>cookies
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/head/title/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>注意：</p> <ul><li>scrapy 中 cookie 不能够放在 headers 中，在构造请求的时候有专门的 cookies 参数，能够接收字典形式的 cookie</li> <li>可能需要在 settings 中设置 ROBOTS 协议、USER_AGENT</li></ul> <h3 id="_2、scrapy-request-发送-post-请求"><a href="#_2、scrapy-request-发送-post-请求" class="header-anchor">#</a> 2、scrapy.Request 发送 post 请求</h3> <p>scrapy.Request 发送 post 请求有两种方式：</p> <ul><li><p>通过 <code>scrapy.Request()</code> 指定 method、body 参数来发送 post 请求（不推荐）</p></li> <li><p>使用 <code>scrapy.FormRequest()</code> 来发送 post 请求（推荐）</p></li></ul> <blockquote><p>注意：<code>scrapy.FormRequest()</code> 能够发送表单和 ajax 请求，参考阅读 <a href="https://www.jb51.net/article/146769.htm" target="_blank" rel="noopener noreferrer">https://www.jb51.net/article/146769.htm<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <p>举例：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">Git2Spider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'git2'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'github.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://github.com/login'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        username <span class="token operator">=</span> <span class="token string">'GitLqr'</span>
        password <span class="token operator">=</span> <span class="token string">'balabala'</span>

        <span class="token comment"># 从登录页面响应中解析出post数据</span>
        token <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//input[@name=&quot;authenticity_token&quot;]/@value'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

        post_data <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">'commit'</span><span class="token punctuation">:</span> <span class="token string">'Sign in'</span><span class="token punctuation">,</span>
            <span class="token string">'authenticity_token'</span><span class="token punctuation">:</span> token<span class="token punctuation">,</span>
            <span class="token string">'login'</span><span class="token punctuation">:</span> username<span class="token punctuation">,</span>
            <span class="token string">'password'</span><span class="token punctuation">:</span> password<span class="token punctuation">,</span>
            <span class="token string">'webauthn-support'</span><span class="token punctuation">:</span> <span class="token string">'supported'</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>post_data<span class="token punctuation">)</span>

        <span class="token comment"># 针对登录url发送post请求</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>
            url<span class="token operator">=</span><span class="token string">'https://github.com/session'</span><span class="token punctuation">,</span>
            callback<span class="token operator">=</span>self<span class="token punctuation">.</span>after_login<span class="token punctuation">,</span>
            formdata<span class="token operator">=</span>post_data
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">after_login</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span><span class="token string">'https://github.com/GitLqr'</span><span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>check_login<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">check_login</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/head/title/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><blockquote><p>注意：在 settings.py 中通过设置 <code>COOKIES_DEBUG = True</code> 能够在终端查看到 cookie 的传递过程</p></blockquote> <h2 id="六、scrapy-管道的使用"><a href="#六、scrapy-管道的使用" class="header-anchor">#</a> 六、scrapy 管道的使用</h2> <h3 id="_1、pipeline-中常用的方法"><a href="#_1、pipeline-中常用的方法" class="header-anchor">#</a> 1、pipeline 中常用的方法</h3> <ul><li><code>process_item(self, item, spider)</code>：
<ul><li>管道类中必须有的函数</li> <li>实现对 item 数据的处理</li> <li>必须 <code>return item</code></li></ul></li> <li><code>open_spider(self, spider)</code>：在爬虫开启的时候仅执行一次</li> <li><code>close_spider(self, spider)</code>：在爬虫关闭的时候仅执行一次</li></ul> <blockquote><p>注意：以上 3 个方法，可以通过 <code>spider.name</code> 获取爬虫的名字</p></blockquote> <h3 id="_2、pipeline-判断数据来源"><a href="#_2、pipeline-判断数据来源" class="header-anchor">#</a> 2、pipeline 判断数据来源</h3> <p>scrapy 的 <code>Item Pipeline</code> 模块可以有多个管道，当有一个 spider 把数据对象通过引擎交给 <code>Item Pipeline</code> 模块时， <code>Item Pipeline</code> 模块中的所有管道会按 <code>settings.py</code> 中指定的管道顺序一一被执行。但很多时候，我们需要管道针对特定爬虫做数据存储的，这时就需要在管道中对数据对象的来源做判断。</p> <blockquote><p>注意：不同的 pipeline 能够对一个或多个爬虫进行不同的数据处理的操作，比如一个进行数据清洗，一个进行数据的保存</p></blockquote> <p>举例：</p> <ul><li>爬虫 1：job.py</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> wangyi<span class="token punctuation">.</span>items <span class="token keyword">import</span> WangyiItem


<span class="token keyword">class</span> <span class="token class-name">JobSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'job'</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">yield</span> item
</code></pre></div><ul><li>爬虫 2：job_simple.py</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> wangyi<span class="token punctuation">.</span>items <span class="token keyword">import</span> WangyiSimpleItem


<span class="token keyword">class</span> <span class="token class-name">JobSimpleSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'job_simple'</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">yield</span> item
</code></pre></div><ul><li>2 个管道：pipelines.py</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">WangyiPipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'wangyi.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job'</span><span class="token punctuation">:</span>
            item <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            str_data <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>item<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">',\n'</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>str_data<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">WangyiSimplePipeline</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job_simple'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'wangyi_simple.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job_simple'</span><span class="token punctuation">:</span>
            item <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
            str_data <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>item<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">',\n'</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>str_data<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'job_simple'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h3 id="_3、pipeline-使用注意点"><a href="#_3、pipeline-使用注意点" class="header-anchor">#</a> 3、pipeline 使用注意点</h3> <ul><li>使用之前需要在 settings 中开启</li> <li>pipeline 在 settings 中键表示位置（即 pipeline 在项目中的位置可以自定义），值表示距离引擎的远近，越近数据会越先经过：<strong>权重值小的优先执行</strong></li> <li>有多个 pipeline 的时候，<code>process_item</code> 的方法必须 <code>return item</code>，否则后一个 pipeline 取到的数据为 None 值</li> <li>pipeline 中 <code>process_item</code> 方法必须要有，否则 item 没有办法接收和处理</li> <li><code>process_item</code> 方法接收 item 和 spider，其中 spider 表示当前传递 item 过来的 spider</li> <li><code>open_spider(spider)</code>：能够在爬虫开启的时候执行一次</li> <li><code>close_spider(spider)</code>：能够在爬虫关闭的时候执行一次</li> <li>上述俩个方法经常用于爬虫和数据库的交互，在爬虫开启的时候建立和数据库的连接，在爬虫关闭的时候断开和数据库的连接</li></ul> <h2 id="七、scrapy-中间件"><a href="#七、scrapy-中间件" class="header-anchor">#</a> 七、scrapy 中间件</h2> <h3 id="_1、介绍"><a href="#_1、介绍" class="header-anchor">#</a> 1、介绍</h3> <h4 id="_1-分类"><a href="#_1-分类" class="header-anchor">#</a> 1）分类</h4> <p>根据 scrapy 运行流程中所在位置不同，对 scrapy 中间件进行分类：</p> <ul><li>下载中间件</li> <li>爬虫中间件</li></ul> <h4 id="_2-作用"><a href="#_2-作用" class="header-anchor">#</a> 2）作用</h4> <p>scrapy 中间件的作用是：预处理 request 和 response 对象</p> <ul><li>对 header 以及 cookie 进行更换和处理</li> <li>使用代理 ip 等</li> <li>对请求进行定制化操作</li></ul> <h4 id="_3-比较"><a href="#_3-比较" class="header-anchor">#</a> 3）比较</h4> <ul><li><p>默认情况下，两种中间件都在 <code>middlewares.py</code> 一个文件中</p></li> <li><p>爬虫中间件使用方法和下载中间件相同，且功能重复，<strong>通常使用下载中间件</strong></p></li></ul> <h3 id="_2、使用方法"><a href="#_2、使用方法" class="header-anchor">#</a> 2、使用方法</h3> <p>注意：结合 scrapy 流程图可方便理解</p> <p><img src="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource20210320170901/image/20210704154838.jpg" alt="scrapy流程图"></p> <p>中间件使用步骤如下：</p> <ol><li><p>在 <code>middlerware.py</code> 中定义中间件类</p></li> <li><p>在中间件类中，重写处理请求或者响应的方法（以<code>Downloader Middlewares</code>为例）</p> <ul><li><p>process_request(self, request, spider)</p> <blockquote><p>当每个 request 通过下载中间件时，该方法被调用【Scrapy Engine --&gt; Downloader】</p></blockquote> <ul><li>返回 None【继续】：该 request 对象通过引擎传递给其他权重低的 <code>process_request</code> 方法，如果所有中间件都返回 None，则请求最终被交给下载器处理。注意：没有 return 也是返回 None。</li> <li>返回 Request 对象【中断】：把 request 对象通过引擎交给调度器，此时将不通过其他权重低的 <code>process_request</code> 方法</li> <li>返回 Response 对象【中断】：<strong>请求不会达到下载器</strong>，会直接把 response 通过引擎交给 Spider 进行解析</li></ul></li> <li><p>process_response(self, request, response, spider)</p> <blockquote><p>当下载器完成 http 请求，传递响应给引擎的时候调用【Scrapy Engine &lt;-- Downloader】</p></blockquote> <ul><li>返回 Request 对象【中断】：通过引擎交给调度器继续请求，此时将不通过其他权重低的 <code>process_response</code> 方法</li> <li>返回 Response 对象【继续】：通过引擎交给爬虫处理或交给权重更低的其他下载中间件的 <code>process_response</code> 方法</li></ul></li></ul></li> <li><p>在 <code>settings</code> 文件中开启中间件，权重值越小越优先执行（同管道注册一样）</p></li></ol> <h3 id="_3、实现随机-user-agent-下载中间件"><a href="#_3、实现随机-user-agent-下载中间件" class="header-anchor">#</a> 3、实现随机 User-Agent 下载中间件</h3> <h4 id="_1-准备-ua-列表"><a href="#_1-准备-ua-列表" class="header-anchor">#</a> 1）准备 UA 列表</h4> <p>在 <code>settings.py</code> 文件中定义一个存放了大量 UA 的列表 <code>USER_AGENT_LIST</code>：</p> <div class="language-python extra-class"><pre class="language-python"><code>USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.72 Safari/537.36'</span>

USER_AGENT_LIST <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0;'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1'</span><span class="token punctuation">,</span>
    <span class="token string">'Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; en) Presto/2.8.131 Version/11.11'</span><span class="token punctuation">,</span>
    <span class="token string">'Opera/9.80 (Windows NT 6.1; U; en) Presto/2.8.131 Version/11.11'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_0) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Maxthon 2.0)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; TencentTraveler 4.0)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; The World)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; SE 2.X MetaSr 1.0; SE 2.X MetaSr 1.0; .NET CLR 2.0.50727; SE 2.X MetaSr 1.0)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; 360SE)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1; Avant Browser)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (iPhone; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (iPod; U; CPU iPhone OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (iPad; U; CPU OS 4_3_3 like Mac OS X; en-us) AppleWebKit/533.17.9 (KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Linux; U; Android 2.3.7; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1'</span><span class="token punctuation">,</span>
    <span class="token string">'MQQBrowser/26 Mozilla/5.0 (Linux; U; Android 2.3.7; zh-cn; MB200 Build/GRJ22; CyanogenMod-7) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1'</span><span class="token punctuation">,</span>
    <span class="token string">'Opera/9.80 (Android 2.3.4; Linux; Opera Mobi/build-1107180945; U; en-GB) Presto/2.8.149 Version/11.10'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (BlackBerry; U; BlackBerry 9800; en) AppleWebKit/534.1+ (KHTML, like Gecko) Version/6.0.0.337 Mobile Safari/534.1+'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.0; U; en-US) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/233.70 Safari/534.6 TouchPad/1.0'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (SymbianOS/9.4; Series60/5.0 NokiaN97-1/20.0.019; Profile/MIDP-2.1 Configuration/CLDC-1.1) AppleWebKit/525 (KHTML, like Gecko) BrowserNG/7.1.18124'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows Phone OS 7.5; Trident/5.0; IEMobile/9.0; HTC; Titan)'</span><span class="token punctuation">,</span>
    <span class="token string">'UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'NOKIA5700/ UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'Openwave/ UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 6.0; ) Opera/UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'NOKIA5700/ UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'Openwave/ UCWEB7.0.2.37/28/999'</span><span class="token punctuation">,</span>
    <span class="token string">'Mozilla/4.0 (compatible; MSIE 6.0; ) Opera/UCWEB7.0.2.37/28/999'</span>
<span class="token punctuation">]</span>
</code></pre></div><blockquote><p>注意：该 <code>USER_AGENT_LIST</code> 变量名可以自定义，也可以写在其他 py 文件中，写在 settings.py 文件中，只是为了规范而已。</p></blockquote> <h4 id="_2-定义下载中间件"><a href="#_2-定义下载中间件" class="header-anchor">#</a> 2）定义下载中间件</h4> <p>在 <code>middlewares.py</code> 文件中定义随机 UA 的下载中间件：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> random

<span class="token keyword">from</span> Douban<span class="token punctuation">.</span>settings <span class="token keyword">import</span> USER_AGENT_LIST


<span class="token keyword">class</span> <span class="token class-name">RandomUserAgentMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># print(request.headers['User-Agent'])</span>
        ua <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>USER_AGENT_LIST<span class="token punctuation">)</span>
        request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">'User-Agent'</span><span class="token punctuation">]</span> <span class="token operator">=</span> ua
</code></pre></div><h4 id="_3-启用下载中间件"><a href="#_3-启用下载中间件" class="header-anchor">#</a> 3）启用下载中间件</h4> <p>在 <code>settings.py</code> 文件中配置开启自定义的下载中间件：</p> <div class="language-python extra-class"><pre class="language-python"><code>DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'Douban.middlewares.RandomUserAgentMiddleware'</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre></div><h3 id="_4、实现-selenium-渲染的下载中间件"><a href="#_4、实现-selenium-渲染的下载中间件" class="header-anchor">#</a> 4、实现 Selenium 渲染的下载中间件</h3> <p>scrapy 的 Downloader 模块只会根据请求获取响应，但实际开发过程中，有些页面上的数据是通过 ajax 延迟加载出来的，Downloader 模块无法应对这种情况，这时就需要用到 Selenium 来处理这类请求，等页面渲染完成后，再把渲染好的页面返回给爬虫即可：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http <span class="token keyword">import</span> HtmlResponse


<span class="token keyword">class</span> <span class="token class-name">SeleniumMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        url <span class="token operator">=</span> request<span class="token punctuation">.</span>url

        <span class="token comment"># 过滤需要使用selenium渲染的request</span>
        <span class="token keyword">if</span> <span class="token string">'daydata'</span> <span class="token keyword">in</span> url<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
            data <span class="token operator">=</span> self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>page_source
            self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 返回HtmlResponse，请求不会达到Downloader，而是直接通过引擎交给爬虫</span>
            response <span class="token operator">=</span> HtmlResponse<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> body<span class="token operator">=</span>data<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">,</span> request<span class="token operator">=</span>request<span class="token punctuation">)</span>
            <span class="token keyword">return</span> response

    <span class="token keyword">def</span> <span class="token function">__del__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></div></div> <div class="page-slot page-slot-bottom"><!-- 横向自适应 -->
      <ins class="adsbygoogle"
          style="display:block"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="6620245489"
          data-ad-format="auto"
          data-full-width-responsive="true"></ins>
      <center><img style="width:100%;" src="https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/FSA_QR_bottom.png"/></center>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script></div> <div class="page-edit"><!----> <div class="tags"><a href="/tags/?tag=Python%E7%88%AC%E8%99%AB" title="标签">#Python爬虫</a><a href="/tags/?tag=Scrapy" title="标签">#Scrapy</a></div> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">2025/07/27, 06:19:32</span></div></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/pages/10277d/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">Python - 爬虫之Selenium</div></a> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/pages/10277d/" class="prev">Python - 爬虫之Selenium</a></span> <!----></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/pages/cfaaca/"><div>
            AI - Gemini CLI 摆脱终端限制
            <!----></div></a> <span class="date">07-27</span></dt></dl><dl><dd>02</dd> <dt><a href="/pages/305cd9/"><div>
            Flutter - 聊天面板库动画生硬？这次让你丝滑个够
            <!----></div></a> <span class="date">07-20</span></dt></dl><dl><dd>03</dd> <dt><a href="/pages/f903b2/"><div>
            Flutter - GetX Helper 如何应用于旧页面
            <!----></div></a> <span class="date">06-14</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><div class="icons"><a href="https://github.com/LinXunFeng" title="GitHub for LinXunFeng" target="_blank" class="iconfont icon-githubsquare"></a><a href="mailto:linxunfeng@yeah.net" title="email for LinXunFeng" target="_blank" class="iconfont icon-youjian"></a><a href="https://github.com/GitLqr" title="GitHub for GitLqr" target="_blank" class="iconfont icon-github-circle"></a></div> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2020-2025
    <span><a href="/about" target="_blank">FSA全栈行动</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <div class="custom-html-window custom-html-window-rb" style="display:;"><div class="custom-wrapper"><span class="close-but">×</span> <div><!-- 固定160*160px -->
      <ins class="adsbygoogle"
          style="display:inline-block;max-width:160px;max-height:160px"
          data-ad-client="ca-pub-7828333725993554"
          data-ad-slot="8377369658"></ins>
      <script>
          (adsbygoogle = window.adsbygoogle || []).push({});
      </script>
      </div></div></div></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.978e7bf8.js" defer></script><script src="/assets/js/2.d8b68cf2.js" defer></script><script src="/assets/js/180.444a244e.js" defer></script>
  </body>
</html>
