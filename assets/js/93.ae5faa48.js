(window.webpackJsonp=window.webpackJsonp||[]).push([[93],{502:function(e,t,a){"use strict";a.r(t);var n=a(21),s=Object(n.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("p",[t("a",{attrs:{href:"https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/04_MediaCapture.html#//apple_ref/doc/uid/TP40010188-CH5-SW2",target:"_blank",rel:"noopener noreferrer"}},[e._v("苹果官方文档-AVFoundation"),t("OutboundLink")],1)]),e._v(" "),t("p",[e._v("为了管理从相机或者麦克风等这样的设备捕获到的信息，我们需要输入对象(input)和输出对象(output)，并且使用一个会话(AVCaptureSession)来管理 input 和 output 之前的数据流：")]),e._v(" "),t("table",[t("thead",[t("tr",[t("th",[e._v("类名")]),e._v(" "),t("th",{staticStyle:{"text-align":"left"}},[e._v("简介")])])]),e._v(" "),t("tbody",[t("tr",[t("td",[e._v("AVCaptureDevice")]),e._v(" "),t("td",{staticStyle:{"text-align":"left"}},[e._v("输入设备，例如 摄像头 麦克风")])]),e._v(" "),t("tr",[t("td",[e._v("AVCaptureInput")]),e._v(" "),t("td",{staticStyle:{"text-align":"left"}},[e._v("输入端口 [使用其子类]")])]),e._v(" "),t("tr",[t("td",[e._v("AVCaptureOutput")]),e._v(" "),t("td",{staticStyle:{"text-align":"left"}},[e._v("设备输出 [使用其子类]，输出视频文件或者静态图像")])]),e._v(" "),t("tr",[t("td",[e._v("AVCaptureSession")]),e._v(" "),t("td",{staticStyle:{"text-align":"left"}},[e._v("管理输入到输出的数据流")])]),e._v(" "),t("tr",[t("td",[e._v("AVCaptureVideoPreviewLayer")]),e._v(" "),t("td",{staticStyle:{"text-align":"left"}},[e._v("展示采集 预览View")])])])]),e._v(" "),t("p",[e._v("如图，通过单个 session，也可以管理多个 input 和 output 对象之间的数据流，从而得到视频、静态图像和预览视图")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/20210110212325.png",alt:"多个输入输出设备"}})]),e._v(" "),t("p",[e._v("如图，input 可以有一个或多个输入端口，output 也可以有一个或多个数据来源（如：一个 "),t("a",{attrs:{href:"https://developer.apple.com/documentation/avfoundation/avcapturemoviefileoutput",target:"_blank",rel:"noopener noreferrer"}},[e._v("AVCaptureMovieFileOutput"),t("OutboundLink")],1),e._v(" 对象可以接收视频数据和音频数据）")]),e._v(" "),t("p",[e._v("当添加 input 和 output 到 session 中时，session 会自动建立起一个连接(AVCaptureConnection)。我们可以使用这个 connection 来设置从 input 或者 从 output 得到的数据的有效性，也可以用来监控在音频信道中功率的平均值和峰值。")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://cdn.jsdelivr.net/gh/FullStackAction/PicBed@resource/image/20210119214239.png",alt:"AVCaptureConnection"}})]),e._v(" "),t("h2",{attrs:{id:"使用-session-来管理数据流"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#使用-session-来管理数据流"}},[e._v("#")]),e._v(" 使用 Session 来管理数据流")]),e._v(" "),t("p",[e._v("创建一个 session 用来管理捕获到的数据，需要先将 inputs 和 outputs 添加到 session 中，当 session 执行 [startRunning] 方法后就会开始将数据流发送至 session，通过执行[stopRunning] 方法来结束数据流的发送。")]),e._v(" "),t("div",{staticClass:"language-objc extra-class"},[t("pre",{pre:!0,attrs:{class:"language-objc"}},[t("code",[e._v("AVCaptureSession "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v("*")]),e._v("captureSession "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("AVCaptureSession alloc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),e._v(" init"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// 添加 inputs 和 outputs")]),e._v("\n\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("session startRunning"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n")])])]),t("p",[e._v("在 [session startRunning] 之前我们需要进行一些基本的配置 (如：设备分辨率，添加输入输出对象等)")]),e._v(" "),t("h3",{attrs:{id:"设置分辨率"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#设置分辨率"}},[e._v("#")]),e._v(" 设置分辨率")]),e._v(" "),t("div",{staticClass:"language-objc extra-class"},[t("pre",{pre:!0,attrs:{class:"language-objc"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// 设置分辨率 720P 标清")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[e._v("if")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("[")]),e._v("captureSession canSetSessionPreset"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(":")]),e._v("AVCaptureSessionPreset1280x720"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("{")]),e._v("\n    captureSession"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(".")]),e._v("sessionPreset "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" AVCaptureSessionPreset1280x720"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("}")]),e._v("\n")])])]),t("p",[e._v("附苹果官方文档中可供配置的分辨率列表")]),e._v(" "),t("p",[t("img",{attrs:{src:"https://linxunfeng.github.io/images/2017/10/iOS-%E8%A7%86%E9%A2%91%E9%87%87%E9%9B%86%E8%AF%A6%E8%A7%A3/3.png",alt:"分辨率列表"}})]),e._v(" "),t("p",[e._v("其中高分辨率(AVCaptureSessionPresetHigh) 为默认值，会根据当前设备进行自适应，但是这样之后导出来的文件就会很大，一般情况下设置为标清(AVCaptureSessionPreset1280x720) 就可以了")]),e._v(" "),t("h3",{attrs:{id:"输入对象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#输入对象"}},[e._v("#")]),e._v(" 输入对象")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 直接使用后置摄像头\nAVCaptureDevice *videoDevice = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo];\n")])])]),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 在这个方法中的 mediaType 有三个选项供我们使用\n// AVMediaTypeVideo 视频\n// AVMediaTypeAudio 音频\n// AVMediaTypeMuxed 混合(视频 + 音频)\n+ (nullable AVCaptureDevice *)defaultDeviceWithMediaType:(AVMediaType)mediaType;\n")])])]),t("p",[e._v("但是这种方式只能获取到后置摄像头，如果想要获取前置摄像头，可使用")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("AVCaptureDevice *videoDevice;\nNSArray *devices = [AVCaptureDevice devices];\nfor (AVCaptureDevice *device in devices) {\n   if(device.position == AVCaptureDevicePositionFront) {\n        // 前置摄像头\n        videoDevice = device;\n   }\n}\n")])])]),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 通过设备获取输入对象\nAVCaptureDeviceInput *videoInput = [AVCaptureDeviceInput deviceInputWithDevice:videoDevice error:nil];\n// 给会话添加输入\nif([captureSession canAddInput:videoInput]) {\n    [captureSession addInput:videoInput];\n}\n")])])]),t("h3",{attrs:{id:"输出对象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#输出对象"}},[e._v("#")]),e._v(" 输出对象")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('// 视频输出：设置视频原数据格式：YUV, RGB \n// 苹果不支持YUV的渲染，只支持RGB渲染，这意味着： YUV => RGB\nAVCaptureVideoDataOutput *videoOutput = [[AVCaptureVideoDataOutput alloc] init];\n\n// videoSettings: 设置视频原数据格式 YUV FULL\nvideoOutput.videoSettings = @{(NSString *)kCVPixelBufferPixelFormatTypeKey:@(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange)};\n\n// 设置代理：获取帧数据\n// 队列：串行/并行，这里使用串行，保证数据顺序 \ndispatch_queue_t queue = dispatch_queue_create("LinXunFengSerialQueue", DISPATCH_QUEUE_SERIAL);\n[videoOutput setSampleBufferDelegate:self queue:queue];\n\n// 给会话添加输出对象\nif([captureSession canAddOutput:videoOutput]) {\n    // 给会话添加输入输出就会自动建立起连接\n    [captureSession addOutput:videoOutput];\n}\n')])])]),t("p",[e._v("在这里，输出对象可以设置帧率")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 帧率：1秒10帧就差不多比较流畅了\nvideoOutput.minFrameDuration = CMTimeMake(1, 10);\n")])])]),t("p",[e._v("输出对象在设置视频原数据格式时使用 videoSettings 属性，需要赋值的类型是字典\n格式有两种，一种是YUV，另一种是RGB（一般我们都使用YUV，因为体积比RGB小）")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// key\nkCVPixelBufferPixelFormatTypeKey 指定解码后的图像格式\n\n// value\nkCVPixelFormatType_420YpCbCr8BiPlanarVideoRange  : YUV420 用于标清视频[420v]\nkCVPixelFormatType_420YpCbCr8BiPlanarFullRange   : YUV422 用于高清视频[420f] \nkCVPixelFormatType_32BGRA : 输出的是BGRA的格式，适用于OpenGL和CoreImage\n\n区别：\n1、前两种是相机输出YUV格式，然后转成RGBA，最后一种是直接输出BGRA，然后转成RGBA;\n2、420v 输出的视频格式为NV12；范围： (luma=[16,235] chroma=[16,240])\n3、420f 输出的视频格式为NV12；范围： (luma=[0,255] chroma=[1,255])\n")])])]),t("h3",{attrs:{id:"预览图层"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#预览图层"}},[e._v("#")]),e._v(" 预览图层")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("AVCaptureVideoPreviewLayer *previewLayer = [AVCaptureVideoPreviewLayer layerWithSession:captureSession];\npreviewLayer.frame = self.view.bounds;\n[self.view.layer  addSublayer:previewLayer];\n")])])]),t("p",[e._v("实时显示摄像头捕获到的图像，但不适用于滤镜渲染")]),e._v(" "),t("h3",{attrs:{id:"代理方法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#代理方法"}},[e._v("#")]),e._v(" 代理方法")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v('#pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate\n/*\n CMSampleBufferRef: 帧缓存数据，描述当前帧信息\n CMSampleBufferGetXXX : 获取帧缓存信息\n CMSampleBufferGetDuration : 获取当前帧播放时间\n CMSampleBufferGetImageBuffer : 获取当前帧图片信息\n */\n// 获取帧数据\n- (void)captureOutput:(AVCaptureOutput *)output didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection {\n    // captureSession 会话如果没有强引用，这里不会得到执行\n    \n    NSLog(@"----- sampleBuffer ----- %@", sampleBuffer);\n}\n')])])]),t("div",{staticClass:"language-objc extra-class"},[t("pre",{pre:!0,attrs:{class:"language-objc"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[e._v("// 获取帧播放时间")]),e._v("\nCMTime duration "),t("span",{pre:!0,attrs:{class:"token operator"}},[e._v("=")]),e._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[e._v("CMSampleBufferGetDuration")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v("(")]),e._v("sampleBuffer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[e._v(";")]),e._v("\n")])])]),t("p",[e._v("在代理方法中，可以把 sampleBuffer 数据渲染出来去显示画面。适用于滤镜渲染")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 获取图片帧数据\nCVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);\nCIImage *ciImage = [CIImage imageWithCVImageBuffer:imageBuffer];\nUIImage *image = [UIImage imageWithCIImage:ciImage];\n\ndispatch_async(dispatch_get_main_queue(), ^{\n    self.imageView.image = image;\n});\n")])])]),t("p",[e._v("需要注意的是：代理方法中的所有动作所在队列都是在异步串行队列中，所以更新UI的操作需要回到主队列中进行！！")]),e._v(" "),t("p",[e._v("但是此时会发现，画面是向左旋转了90度，因为默认采集的视频是横屏的，需要我们进一步做调整。以下步骤添加在[session startRunning];之前即可，但是一定要在添加了 input 和 output之后～")]),e._v(" "),t("div",{staticClass:"language-objective-c extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[e._v("// 获取输入与输出之间的连接\nAVCaptureConnection *connection = [videoOutput connectionWithMediaType:AVMediaTypeVideo];\n// 设置采集数据的方向\nconnection.videoOrientation = AVCaptureVideoOrientationPortrait;\n// 设置镜像效果镜像\nconnection.videoMirrored = YES;\n")])])]),t("h2",{attrs:{id:"demo"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#demo"}},[e._v("#")]),e._v(" Demo")]),e._v(" "),t("p",[t("a",{attrs:{href:"https://github.com/LinXunFeng/LXFAudioVideo",target:"_blank",rel:"noopener noreferrer"}},[e._v("LXFAudioVideo"),t("OutboundLink")],1)])])}),[],!1,null,null,null);t.default=s.exports}}]);